{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load(\"train.dat.npz\")\n",
    "train_users = data[\"users\"]\n",
    "train_tokens = data[\"users_tokens\"]\n",
    "del(data)\n",
    "data = np.load(\"test.dat.npz\")\n",
    "test_users = data[\"users\"]\n",
    "test_tokens = data[\"users_tokens\"]\n",
    "del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_SET_URL = \"../twitter_train.csv\"\n",
    "TESTING_SET_URL = \"../twitter_test.csv\"\n",
    "df_train = pd.read_csv(TRAINING_SET_URL)\n",
    "df_test = pd.read_csv(TESTING_SET_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x[0] == 1:\n",
    "        return 1\n",
    "    if x[1] == 1:\n",
    "        return 2\n",
    "    if x[2] == 1:\n",
    "        return 3\n",
    "\n",
    "Y = df_train[['is_1', 'is_2', 'is_3']].apply(f, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = DictVectorizer()\n",
    "X = v.fit_transform(np.append(train_tokens, test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_counts = np.asarray((X > 0).sum(axis=0)).ravel()\n",
    "X_tmp = X.tocsc()[:, features_counts > 200].toarray()\n",
    "train_x = X_tmp[:train_users.size]\n",
    "test_x = X_tmp[train_users.size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "train_x_tfidf = tfidf.fit_transform(train_x)\n",
    "test_x_tfidf = tfidf.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_x_tfidf, Y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_to_vw(data, fname, target=None):\n",
    "    with open(fname, 'w') as fout:\n",
    "        for i, tokens in enumerate(data):\n",
    "            text = ' '.join([word for word in tokens.keys() if not word.isnumeric() and len(word) > 3])\n",
    "            if target is not None:\n",
    "                fout.write('{0} |t {1}\\n'.format(target[i], text))\n",
    "            else:\n",
    "                fout.write('|t {0}\\n'.format(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_vw_tf(data, fname, target=None):\n",
    "    with open(fname, 'w') as fout:\n",
    "        for i, row in enumerate(data):\n",
    "            s = ''\n",
    "            if target is not None:\n",
    "                s = '%s ' % target[i]\n",
    "            for j, word in enumerate(row):\n",
    "                s += '|{0} {1} '.format(j, word)\n",
    "            \n",
    "            fout.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_normalized_wv_pred(fname):\n",
    "    pred_vw_raw = pd.read_table(fname, sep=' |:', engine='python', header=None)[[1, 3, 5]].values\n",
    "    pred_vw = expit(pred_vw_raw)\n",
    "    for i in range(pred_vw.shape[0]):\n",
    "        s = pred_vw[i].sum()\n",
    "        for j in range(pred_vw.shape[1]):\n",
    "            pred_vw[i, j] = pred_vw[i, j] / s\n",
    "        \n",
    "    return pred_vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(np.arange(train_tokens.size), test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_to_vw_tf(train_x_tfidf.toarray(), \"train.vw\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to_vw_tf(test_x_tfidf.toarray(), \"test.vw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "0.333333   0.333333          3      3.0          3        3     2419\n",
      "0.166667   0.000000          6      6.0          3        3     2419\n",
      "0.272727   0.400000         11     11.0          3        3     2419\n",
      "0.590909   0.909091         22     22.0          1        3     2419\n",
      "0.590909   0.590909         44     44.0          1        3     2419\n",
      "0.540230   0.488372         87     87.0          3        3     2419\n",
      "0.540230   0.540230        174    174.0          1        3     2419\n",
      "0.557471   0.574713        348    348.0          3        3     2419\n",
      "0.574713   0.591954        696    696.0          1        1     2419\n",
      "0.555316   0.535920       1392   1392.0          2        3     2419\n",
      "0.549569   0.543822       2784   2784.0          2        1     2419\n",
      "0.524246   0.498922       5568   5568.0          2        1     2419\n",
      "0.474899   0.425543      11135  11135.0          1        3     2419\n",
      "0.397638   0.320370      22269  22269.0          1        1     2419\n",
      "0.313919   0.230196      44537  44537.0          1        1     2419\n",
      "0.199196   0.084471      89073  89073.0          3        3     2419\n",
      "\n",
      "finished run\n",
      "number of examples = 150000\n",
      "weighted example sum = 150000\n",
      "weighted label sum = 0\n",
      "average loss = 0.126227\n",
      "best constant = 0\n",
      "total feature number = 362850000\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 50 --loss_function logistic --oaa 3 --nn 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "raw predictions = pred.txt\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.000000   1.000000          3      3.0         -1        3     2419\n",
      "1.000000   1.000000          6      6.0         -1        3     2419\n",
      "1.000000   1.000000         11     11.0         -1        1     2419\n",
      "1.000000   1.000000         22     22.0         -1        1     2419\n",
      "1.000000   1.000000         44     44.0         -1        1     2419\n",
      "1.000000   1.000000         87     87.0         -1        1     2419\n",
      "1.000000   1.000000        174    174.0         -1        3     2419\n",
      "1.000000   1.000000        348    348.0         -1        3     2419\n",
      "1.000000   1.000000        696    696.0         -1        1     2419\n",
      "1.000000   1.000000       1392   1392.0         -1        1     2419\n",
      "\n",
      "finished run\n",
      "number of examples = 2000\n",
      "weighted example sum = 2000\n",
      "weighted label sum = 0\n",
      "average loss = 1\n",
      "best constant = -0.00050025\n",
      "total feature number = 4838000\n"
     ]
    }
   ],
   "source": [
    "!vw -d test.vw -i model.vw -t -r pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_vw = get_normalized_wv_pred(\"pred.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(train_x_tfidf, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80953145377040381"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, gbc.predict_proba(x_test.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = gbc.predict_proba(test_x_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x_tfidf, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss(y_test, clf.predict_proba(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = clf.predict_proba(test_x_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = np.ones((test_users.size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_df['twitter_id'] = test_users\n",
    "pred_df['is_1'] = Y_pred[:, 0]\n",
    "pred_df['is_2'] = Y_pred[:, 1]\n",
    "pred_df['is_3'] = Y_pred[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
